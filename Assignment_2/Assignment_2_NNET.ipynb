{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File: NNnet_training.py\n",
    "Author: Muhammad Haris Masood\n",
    "Date: February 27, 2024\n",
    "Description: The script trains a neural net classifier for hotel cancellation dataset\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from mlrose_hiive import NeuralNetwork,relu,sigmoid\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Function to load and prepare the hotel dataset\n",
    "def load_hotel():\n",
    "\n",
    "    '''Load Hotel Dataset\n",
    "    \n",
    "    Returns:\n",
    "    X (np.array): X array\n",
    "    Y (np.array): Y array\n",
    "    col_index (dict): Dictionary containing the pairing for the column location and it's name'''\n",
    "    \n",
    "    #PLEASE CHANGE TO LOCATION OF YOUR HOTEL DATA\n",
    "    df=pd.read_csv('Data/Hotel_Res/Hotel Reservations.csv')\n",
    "    df=df.drop('arrival_year',axis=1) #Remove Year\n",
    "    df['season']=df['arrival_month'].apply(lambda x:1 if (x>=4 and x<=9) else 0) #0-Summer, 1-Winter\n",
    "    df.drop('arrival_month',inplace=True,axis=1)\n",
    "    df['point_in_month']=df['arrival_date'].apply(lambda x:1 if (x<=15) else 0) #0-eralier in the month,1-later\n",
    "\n",
    "    #Removing Booking ID as it not a usefull feature\n",
    "    df=df.drop('Booking_ID',axis=1)\n",
    "\n",
    "    #Creating the labels (Y)\n",
    "    Y=np.array(df['booking_status'].apply(lambda x:0 if x=='Not_Canceled' else 1)) #0 if not canceled, 1 if canceled\n",
    "\n",
    "    df.drop('booking_status',inplace=True,axis=1)\n",
    "\n",
    "    #Creating the feature vector, X \n",
    "    label_columns=['booking_status']\n",
    "    categorical_columns=['type_of_meal_plan', 'room_type_reserved', 'market_segment_type']\n",
    "    non_categorical_variables=list(set(df.columns).difference(set(categorical_columns+label_columns)))\n",
    "    X=np.array(df[non_categorical_variables])\n",
    "    columns_categorized=non_categorical_variables\n",
    "\n",
    "    #Now we need to one hot vectorize the type_of_meal_plan, room_type_reserved and market_segment_type\n",
    "    label_dict={}\n",
    "    for i in categorical_columns:\n",
    "        label_dict[i]=OneHotEncoder()\n",
    "        res=label_dict[i].fit_transform(np.array(df[i]).reshape(-1,1)).toarray()\n",
    "        X=np.c_[X,res]\n",
    "        columns_categorized=columns_categorized+[i+'%'+j for j in ['1','2','3','4','5','6','7'][:res.shape[-1]]]\n",
    "\n",
    "        col_index={}\n",
    "        results_corr={}\n",
    "        for label,col in zip(columns_categorized,range(X.shape[-1])):\n",
    "            corr=scipy.stats.pearsonr(X[:,col],Y)[0]\n",
    "            results_corr[label]=corr\n",
    "            col_index[label]=col\n",
    "    return X,Y,col_index\n",
    "\n",
    "#Load Heart Disease Data\n",
    "def load_heart_data():\n",
    "\n",
    "    '''Load Heart Disease Dataset\n",
    "    \n",
    "    Returns:\n",
    "    X (np.array): X array\n",
    "    Y (np.array): Y array\n",
    "    col_index (dict): Dictionary containing the pairing for the column location and it's name'''\n",
    "\n",
    "    #PLEASE CHANGE TO LOCATION OF YOUR HEART DATA\n",
    "    df=pd.read_csv('Data/Heart/heart.csv')\n",
    "    Y=np.array(df['HeartDisease'])\n",
    "    df.drop('HeartDisease',axis=1,inplace=True)\n",
    "    \n",
    "    label_columns=['HeartDisease']\n",
    "    categorical_columns=['Sex', 'ChestPainType', 'RestingECG','ExerciseAngina','ST_Slope']\n",
    "\n",
    "    non_categorical_variables=list(set(df.columns).difference(set(categorical_columns+label_columns)))\n",
    "    X=np.array(df[non_categorical_variables])\n",
    "    columns_categorized=non_categorical_variables\n",
    "\n",
    "    #Now we need to one hot vectorize the type_of_meal_plan, room_type_reserved and market_segment_type\n",
    "    label_dict={}\n",
    "    for i in categorical_columns:\n",
    "        label_dict[i]=OneHotEncoder()\n",
    "        res=label_dict[i].fit_transform(np.array(df[i]).reshape(-1,1)).toarray()\n",
    "        X=np.c_[X,res]\n",
    "        columns_categorized=columns_categorized+[i+'%'+j for j in ['1','2','3','4','5','6','7'][:res.shape[-1]]]\n",
    "\n",
    "        col_index={}\n",
    "        results_corr={}\n",
    "        for label,col in zip(columns_categorized,range(X.shape[-1])):\n",
    "            corr=scipy.stats.pearsonr(X[:,col],Y)[0]\n",
    "            results_corr[label]=corr\n",
    "            col_index[label]=col\n",
    "    return X,Y,col_index\n",
    "\n",
    "\n",
    "def split_data(X,Y,valid=True,standardize=False):\n",
    "\n",
    "    '''\n",
    "    Split the data between train, test and optional validation dataset\n",
    "\n",
    "    Parameters:\n",
    "    X (np.array): X features\n",
    "    Y (np.rray): Labels\n",
    "    valid (bool): Split into validation dataset \n",
    "    standardize (bool): Whether to standardize the data (introduces bias as Sklearn Standard Scaler is trained only on the train data)\n",
    "\n",
    "    Returns:\n",
    "    train (list): np.array list of train\n",
    "    valid (list): optional np.array list of validation\n",
    "    test (list): np.array list of test\n",
    "    '''\n",
    "    \n",
    "    #Now let's split the data between test and train, we'll use the standard 80/20 split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,random_state=42)\n",
    "    \n",
    "    if valid:\n",
    "        #We'll also split the data between train and validation, we'll again use the standard 80/20 split\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2,random_state=42)\n",
    "        \n",
    "        if standardize:\n",
    "            sklr=StandardScaler()\n",
    "            X_train=sklr.fit_transform(X_train)\n",
    "            X_valid=sklr.transform(X_valid)\n",
    "            X_test=sklr.transform(X_test)\n",
    "        return [X_train,y_train],[X_valid,y_valid],[X_test,y_test]\n",
    "\n",
    "    if standardize:\n",
    "        sklr=StandardScaler()\n",
    "        X_train=sklr.fit_transform(X_train)\n",
    "        X_test=sklr.transform(X_test)\n",
    "    return [X_train,y_train],[X_test,y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hotel\n",
    "X_hotel,Y_hotel,col_index_hotel=load_hotel()\n",
    "train_hotel,test_hotel=split_data(X_hotel,Y_hotel,valid=False)\n",
    "\n",
    "#Heart\n",
    "X_heart,Y_heart,col_index_heart=load_heart_data()\n",
    "train_heart,test_heart=split_data(X_heart,Y_heart,valid=False)\n",
    "\n",
    "#Base\n",
    "sklr_hotel=StandardScaler()\n",
    "sklr_heart=StandardScaler()\n",
    "\n",
    "#Hotel\n",
    "train_hotel_standardized=train_hotel.copy()\n",
    "train_hotel_unstandardized=train_hotel.copy()\n",
    "\n",
    "test_hotel_standardized=test_hotel.copy()\n",
    "\n",
    "train_hotel_standardized[0]=sklr_hotel.fit_transform(train_hotel[0])\n",
    "test_hotel_standardized[0]=sklr_hotel.transform(test_hotel[0])\n",
    "\n",
    "#Heart\n",
    "train_heart_standardized=train_heart.copy()\n",
    "\n",
    "test_heart_standardized=test_heart.copy()\n",
    "\n",
    "train_heart_standardized[0]=sklr_heart.fit_transform(train_heart[0])\n",
    "test_heart_standardized[0]=sklr_heart.transform(test_heart[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'internal_layers': 4, 'learning_rate': 0.0001, 'units': 100, 'internal_activation':relu, 'final_activation':sigmoid, 'l1/l2/dropout':0}\n",
    "internal_layers=1\n",
    "learning_rate=0.0001\n",
    "units=256\n",
    "internal_activation='relu'\n",
    "final_activation='sigmoid'\n",
    "arch=[units]*internal_layers\n",
    "\n",
    "#CCreating the RHC Classifier\n",
    "classifier=NeuralNetwork(\n",
    "    algorithm='random_hill_climb',\n",
    "    restarts=5,\n",
    "    #algorithm='gradient_descent',\n",
    "    hidden_nodes=arch,\n",
    "    learning_rate=learning_rate,\n",
    "    activation=internal_activation,\n",
    "    curve=True,\n",
    "    max_attempts=10,\n",
    "    max_iters=10000,\n",
    "    early_stopping=True,\n",
    "    clip_max = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=classifier.fit(train_heart_standardized[0],train_heart_standardized[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7343324250681199"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(classifier.predict(train_heart_standardized[0]),train_heart_standardized[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6304347826086957"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(classifier.predict(test_heart_standardized[0]),test_heart_standardized[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2968586303852727"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.95463777e+00, 1.49527000e+05],\n",
       "       [8.95461477e+00, 1.49529000e+05],\n",
       "       [8.95461477e+00, 1.49530000e+05],\n",
       "       ...,\n",
       "       [8.92247208e+00, 1.64402000e+05],\n",
       "       [8.92247208e+00, 1.64403000e+05],\n",
       "       [8.92247208e+00, 1.64404000e+05]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fitness_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict={\n",
    "    'training_time':5,\n",
    "    'training_accuracy':0.85,\n",
    "    'test_accuracy':0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training_time</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training_accuracy</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0     1\n",
       "0      training_time  5.00\n",
       "1  training_accuracy  0.85\n",
       "2      test_accuracy  0.90"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
